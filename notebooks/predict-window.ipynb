{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime \n",
    "from datetime import timezone\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.utils.data as data_utils \n",
    "import cryptocompare\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and intialize the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, \n",
    "                 activation_function = nn.ReLU,\n",
    "                 optimizer = Adam,\n",
    "                 dropout = 0.2\n",
    "                ):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        input_dim = 14\n",
    "        hidden_dim = 100\n",
    "        output_dim = 1\n",
    "        self.lstm1 = nn.LSTM(input_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(p = dropout)\n",
    "        self.lstm2 = nn.LSTM(hidden_dim, hidden_dim)\n",
    "        self.layers =[nn.Dropout(p = dropout)]\n",
    "        self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x.view(len(x), 1 , -1))\n",
    "        out = self.dropout1(out.view(len(x), -1))\n",
    "        out, _ = self.lstm2(out.view(len(x), 1 , -1))\n",
    "        out = self.layers(out.view(len(x), -1))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1623621600.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = cryptocompare.get_historical_price_day('BTC', 'USD', limit=2000, exchange='CCCAGG')\n",
    "datetime.timestamp(datetime(2021,6,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Data api crypto compare \n",
    "def get_data(start_date,end_date,crypto):\n",
    "    l=[]\n",
    "    i=0\n",
    "\n",
    "    while start_date>=end_date:\n",
    "        i=i+1\n",
    "        print(\"requette :\",i)\n",
    "        try : \n",
    "            data = cryptocompare.get_historical_price_day(crypto, 'USD', limit=2000, exchange='CCCAGG', toTs=start_date)\n",
    "            if data is None : \n",
    "                raise ValueError \n",
    "        except: \n",
    "            break\n",
    "\n",
    "        l=data+l\n",
    "        start_date=datetime.fromtimestamp(data[0]['time'])\n",
    "    df = pd.DataFrame.from_dict(l)\n",
    "    df=df.iloc[:,:7]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#const\n",
    "START_DATE=datetime.now()\n",
    "END_DATE=datetime(2010,6,18)\n",
    "CRYPTO='ETH'\n",
    "#PATHz='/home/jbouhadoun/esgi/PA5_Crypto-Advice/src/scrapper/outputs/ltc_2018-01-01_2021-06-25.csv'\n",
    "PATH_BTC=\"/home/jbouhadoun/Téléchargements/histo_eth (1).csv\"\n",
    "PATH_BTC_TWEET=\"/home/jbouhadoun/esgi/exp/final_data/historical_eth_twitter_withsentiment.csv\"\n",
    "PATH_MODEL_BTC=\"\"\n",
    "PATH_scaler_BTC=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(PATH):\n",
    "    df=pd.read_csv(PATH)\n",
    "    df=df.fillna(df.mean())\n",
    "    df=df.iloc[:,2:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_tweet(PATH):\n",
    "    df_tweet=pd.read_csv(PATH)\n",
    "    df_tweet=df_tweet.groupby(\"time\",as_index=False)[\"sentiment_analysis\"].mean()\n",
    "    df_tweet['time'] = pd.to_datetime(df_tweet['time'], format=\"%Y-%m-%d\")\n",
    "    df_tweet['time'] = df_tweet['time'].apply(lambda x: int(x.replace(tzinfo=timezone.utc).timestamp()))\n",
    "    return df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1483228800</td>\n",
       "      <td>0.120282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1483315200</td>\n",
       "      <td>0.054745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1483401600</td>\n",
       "      <td>0.127372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1483488000</td>\n",
       "      <td>0.063388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1483574400</td>\n",
       "      <td>0.096465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1624492800</td>\n",
       "      <td>0.129996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>1624579200</td>\n",
       "      <td>0.121893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>1624665600</td>\n",
       "      <td>0.106218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1624752000</td>\n",
       "      <td>0.125983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>1624838400</td>\n",
       "      <td>0.036252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1453 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time  sentiment_analysis\n",
       "0     1483228800            0.120282\n",
       "1     1483315200            0.054745\n",
       "2     1483401600            0.127372\n",
       "3     1483488000            0.063388\n",
       "4     1483574400            0.096465\n",
       "...          ...                 ...\n",
       "1448  1624492800            0.129996\n",
       "1449  1624579200            0.121893\n",
       "1450  1624665600            0.106218\n",
       "1451  1624752000            0.125983\n",
       "1452  1624838400            0.036252\n",
       "\n",
       "[1453 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T=read_csv_tweet(PATH_BTC_TWEET)\n",
    "#!!!!warning\n",
    "#T.to_csv(\"/home/jbouhadoun/esgi/exp/final_data/historical_tweet_eth_final_timestamp.csv\")\n",
    "#T[\"Text\"]=T[\"Text\"].replace(r\"\\n{2,}\",\"\\n\")\n",
    "#T[\"Embtext\"]=T[\"Embtext\"].replace(r\"\\n{2,}\",\"\\n\")\n",
    "#T=T.drop(columns=[\"Unnamed: 0\"])\n",
    "#T.to_csv(\"/home/jbouhadoun/esgi/exp/final_data/historical_tweet_eth_final_timestamp_chariots.csv\",index=False)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(df,df1,df2):\n",
    "    df_merge=pd.merge(df,df1,on=\"time\")\n",
    "    df_merge_2=pd.merge(df_merge,df2,on='time')\n",
    "    df_merge=df_merge_2\n",
    "    df_merge[\"time\"]=pd.to_datetime(df_merge[\"time\"], unit='s')\n",
    "    df_merge = df_merge.set_index('time')\n",
    "    df_merge.index = pd.to_datetime(df_merge.index, unit='s')\n",
    "    return df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, train_prop=100):\n",
    "    train_data = data.iloc[:int(train_prop * len(data))]\n",
    "    test_data = data.iloc[int(train_prop * len(data)):]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(traindf,min_max_scaler=None):\n",
    "    x = traindf.values\n",
    "    if min_max_scaler is None:\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        min_max_scaler.fit(x)\n",
    "    x_scaled=min_max_scaler.transform(traindf.values)\n",
    "    normalized_df = pd.DataFrame(x_scaled, columns = traindf.columns)\n",
    "    return normalized_df,min_max_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_data(min_max_scaler, normalized_df):\n",
    "    new_x = normalized_df.values* (min_max_scaler.data_max_-min_max_scaler.data_min_) + min_max_scaler.data_min_\n",
    "    return pd.DataFrame(new_x, columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_window_data(df, window_len=5, zero_base=True):\n",
    "    window_data = []\n",
    "    for idx in range(len(df) - window_len):\n",
    "        tmp = df[idx: (idx + window_len)].copy()\n",
    "        if zero_base:\n",
    "            tmp = normalise_zero_base(tmp)\n",
    "        window_data.append(tmp.values)\n",
    "    return np.array(window_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(train_data,test_data,to_plot, labels, title='', x_label='', y_label=''):\n",
    "    fig, ax = plt.subplots(1, figsize=(14, 7))\n",
    "    for i in range(len(to_plot)):\n",
    "        ax.plot(to_plot[i], label=labels[i])\n",
    "    \n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "############plot_curves([train_data['close'], test_data['close']], ['training', 'test'], title='btc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(train_normalized):\n",
    "    train_target_tensor = torch.tensor(train_normalized['close'].values.astype(np.float64))\n",
    "    train_data_tensor = torch.tensor(train_normalized.drop('close', axis = 1).values) \n",
    "    train_tensor = data_utils.TensorDataset(train_data_tensor, train_target_tensor) \n",
    "    train_loader = data_utils.DataLoader(dataset = train_tensor, batch_size = 32, shuffle = True)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def create_data_loader_test(test_data,scaler):\n",
    "    test_normalized,_ = normalize_data(test_data,scaler)\n",
    "    test_target = torch.tensor(test_normalized['close'].values.astype(np.float64))\n",
    "    test = torch.tensor(test_normalized.drop('close', axis = 1).values) \n",
    "    print(test_target[0])\n",
    "    test_tensor = data_utils.TensorDataset(test, test_target) \n",
    "    test_loader = data_utils.DataLoader(dataset = test_tensor, batch_size = 32, shuffle = False)\n",
    "    return test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def model(train_loader,epochs=1000):\n",
    "    model = NeuralNet()\n",
    "\n",
    "    EPOCHS = epochs\n",
    "\n",
    "    #target = pd.DataFrame(data = train_normalized['close'])\n",
    "\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_loss = 0\n",
    "        for bidx, batch in tqdm(enumerate(train_loader)):\n",
    "            X, Y = batch\n",
    "            model.zero_grad()\n",
    "            loss = 0\n",
    "            for i in range(len(X)):\n",
    "                x, y = X[i], Y[i]\n",
    "                x = x.view(-1, len(x))\n",
    "\n",
    "                #Forward Pass\n",
    "                y_hat = model(x.float())\n",
    "\n",
    "                #Loss\n",
    "                loss += criterion(y.float(), y_hat.float())\n",
    "\n",
    "            #Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            #Parameters optimization\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += float(loss)\n",
    "\n",
    "        losses.append(epoch_loss)\n",
    "        model_close=model\n",
    "        print(\"Epoch \", epoch, \": \", epoch_loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,test_loader,scaler):\n",
    "    y_list = []\n",
    "    y_hat_list = []\n",
    "    min_max_scaler=scaler\n",
    "    for bidx, batch in tqdm(enumerate(test_loader)):\n",
    "            X, Y = batch\n",
    "            for i in range(len(X)):\n",
    "                x, y = X[i], Y[i]\n",
    "                x = x.view(-1, len(x))\n",
    "                y_hat = model(x.float())\n",
    "                \n",
    "                print(y_hat)\n",
    "                vmin = min_max_scaler.data_min_[5]\n",
    "                vmax = min_max_scaler.data_max_[5]\n",
    "                y_hat_list.append(float(y_hat)* (vmax - vmin) + vmin)\n",
    "    return y_hat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requette : 1\n",
      "requette : 2\n",
      "requette : 3\n",
      "tensor(0.5663, dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volumefrom</th>\n",
       "      <th>volumeto</th>\n",
       "      <th>close</th>\n",
       "      <th>addresses_active_count</th>\n",
       "      <th>addresses_new_non_zero_count</th>\n",
       "      <th>addresses_count</th>\n",
       "      <th>addresses_receiving_count</th>\n",
       "      <th>addresses_sending_count</th>\n",
       "      <th>transactions_transfers_volume_sum</th>\n",
       "      <th>mining_hash_rate_mean</th>\n",
       "      <th>mining_difficulty_latest</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>8.891</td>\n",
       "      <td>7.970</td>\n",
       "      <td>8.018</td>\n",
       "      <td>854000.05</td>\n",
       "      <td>6.963217e+06</td>\n",
       "      <td>8.154</td>\n",
       "      <td>13695</td>\n",
       "      <td>1357</td>\n",
       "      <td>729071</td>\n",
       "      <td>12933</td>\n",
       "      <td>6215</td>\n",
       "      <td>1.818131e+06</td>\n",
       "      <td>5.646216e+12</td>\n",
       "      <td>8.174688e+13</td>\n",
       "      <td>0.120282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>8.568</td>\n",
       "      <td>7.964</td>\n",
       "      <td>8.154</td>\n",
       "      <td>859902.07</td>\n",
       "      <td>7.152179e+06</td>\n",
       "      <td>8.317</td>\n",
       "      <td>14916</td>\n",
       "      <td>1901</td>\n",
       "      <td>730972</td>\n",
       "      <td>13899</td>\n",
       "      <td>7320</td>\n",
       "      <td>2.857197e+06</td>\n",
       "      <td>5.646488e+12</td>\n",
       "      <td>8.278692e+13</td>\n",
       "      <td>0.054745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>9.940</td>\n",
       "      <td>8.185</td>\n",
       "      <td>8.335</td>\n",
       "      <td>571218.00</td>\n",
       "      <td>5.292232e+06</td>\n",
       "      <td>9.595</td>\n",
       "      <td>14612</td>\n",
       "      <td>2518</td>\n",
       "      <td>733490</td>\n",
       "      <td>13201</td>\n",
       "      <td>8236</td>\n",
       "      <td>5.066915e+06</td>\n",
       "      <td>5.623616e+12</td>\n",
       "      <td>8.197531e+13</td>\n",
       "      <td>0.127372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>11.500</td>\n",
       "      <td>10.240</td>\n",
       "      <td>9.639</td>\n",
       "      <td>2063444.32</td>\n",
       "      <td>2.269524e+07</td>\n",
       "      <td>11.000</td>\n",
       "      <td>17688</td>\n",
       "      <td>3245</td>\n",
       "      <td>736735</td>\n",
       "      <td>15979</td>\n",
       "      <td>10535</td>\n",
       "      <td>7.864367e+06</td>\n",
       "      <td>6.200869e+12</td>\n",
       "      <td>8.832221e+13</td>\n",
       "      <td>0.063388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>10.370</td>\n",
       "      <td>9.151</td>\n",
       "      <td>11.000</td>\n",
       "      <td>2134380.99</td>\n",
       "      <td>2.160218e+07</td>\n",
       "      <td>10.120</td>\n",
       "      <td>18556</td>\n",
       "      <td>3123</td>\n",
       "      <td>739858</td>\n",
       "      <td>16927</td>\n",
       "      <td>9962</td>\n",
       "      <td>8.078451e+06</td>\n",
       "      <td>6.344418e+12</td>\n",
       "      <td>9.108022e+13</td>\n",
       "      <td>0.096465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-22</th>\n",
       "      <td>1998.750</td>\n",
       "      <td>1705.780</td>\n",
       "      <td>1887.890</td>\n",
       "      <td>1703182.02</td>\n",
       "      <td>3.161540e+09</td>\n",
       "      <td>1880.830</td>\n",
       "      <td>516669</td>\n",
       "      <td>91165</td>\n",
       "      <td>120604388</td>\n",
       "      <td>268881</td>\n",
       "      <td>247278</td>\n",
       "      <td>5.269369e+06</td>\n",
       "      <td>4.889401e+14</td>\n",
       "      <td>6.623077e+15</td>\n",
       "      <td>0.105962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23</th>\n",
       "      <td>2044.910</td>\n",
       "      <td>1827.200</td>\n",
       "      <td>1880.830</td>\n",
       "      <td>714905.63</td>\n",
       "      <td>1.416402e+09</td>\n",
       "      <td>1968.560</td>\n",
       "      <td>512525</td>\n",
       "      <td>88383</td>\n",
       "      <td>120692771</td>\n",
       "      <td>246050</td>\n",
       "      <td>251778</td>\n",
       "      <td>2.275053e+06</td>\n",
       "      <td>4.735033e+14</td>\n",
       "      <td>6.530681e+15</td>\n",
       "      <td>0.072830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-24</th>\n",
       "      <td>2034.570</td>\n",
       "      <td>1886.170</td>\n",
       "      <td>1968.560</td>\n",
       "      <td>448512.52</td>\n",
       "      <td>8.825040e+08</td>\n",
       "      <td>1989.010</td>\n",
       "      <td>523980</td>\n",
       "      <td>92943</td>\n",
       "      <td>120785714</td>\n",
       "      <td>239936</td>\n",
       "      <td>270342</td>\n",
       "      <td>2.544816e+06</td>\n",
       "      <td>4.731043e+14</td>\n",
       "      <td>6.420884e+15</td>\n",
       "      <td>0.129996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>2019.450</td>\n",
       "      <td>1791.990</td>\n",
       "      <td>1989.010</td>\n",
       "      <td>882983.22</td>\n",
       "      <td>1.653238e+09</td>\n",
       "      <td>1810.270</td>\n",
       "      <td>454887</td>\n",
       "      <td>84717</td>\n",
       "      <td>120870431</td>\n",
       "      <td>226995</td>\n",
       "      <td>228460</td>\n",
       "      <td>2.672925e+06</td>\n",
       "      <td>4.611892e+14</td>\n",
       "      <td>6.084097e+15</td>\n",
       "      <td>0.121893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-26</th>\n",
       "      <td>1851.360</td>\n",
       "      <td>1717.910</td>\n",
       "      <td>1810.270</td>\n",
       "      <td>575329.88</td>\n",
       "      <td>1.021388e+09</td>\n",
       "      <td>1830.940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120870431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.964921e+06</td>\n",
       "      <td>1.433537e+14</td>\n",
       "      <td>2.051046e+15</td>\n",
       "      <td>0.106218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1451 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                high       low      open  volumefrom      volumeto     close  \\\n",
       "time                                                                           \n",
       "2017-01-01     8.891     7.970     8.018   854000.05  6.963217e+06     8.154   \n",
       "2017-01-02     8.568     7.964     8.154   859902.07  7.152179e+06     8.317   \n",
       "2017-01-03     9.940     8.185     8.335   571218.00  5.292232e+06     9.595   \n",
       "2017-01-04    11.500    10.240     9.639  2063444.32  2.269524e+07    11.000   \n",
       "2017-01-05    10.370     9.151    11.000  2134380.99  2.160218e+07    10.120   \n",
       "...              ...       ...       ...         ...           ...       ...   \n",
       "2021-06-22  1998.750  1705.780  1887.890  1703182.02  3.161540e+09  1880.830   \n",
       "2021-06-23  2044.910  1827.200  1880.830   714905.63  1.416402e+09  1968.560   \n",
       "2021-06-24  2034.570  1886.170  1968.560   448512.52  8.825040e+08  1989.010   \n",
       "2021-06-25  2019.450  1791.990  1989.010   882983.22  1.653238e+09  1810.270   \n",
       "2021-06-26  1851.360  1717.910  1810.270   575329.88  1.021388e+09  1830.940   \n",
       "\n",
       "            addresses_active_count  addresses_new_non_zero_count  \\\n",
       "time                                                               \n",
       "2017-01-01                   13695                          1357   \n",
       "2017-01-02                   14916                          1901   \n",
       "2017-01-03                   14612                          2518   \n",
       "2017-01-04                   17688                          3245   \n",
       "2017-01-05                   18556                          3123   \n",
       "...                            ...                           ...   \n",
       "2021-06-22                  516669                         91165   \n",
       "2021-06-23                  512525                         88383   \n",
       "2021-06-24                  523980                         92943   \n",
       "2021-06-25                  454887                         84717   \n",
       "2021-06-26                       0                             0   \n",
       "\n",
       "            addresses_count  addresses_receiving_count  \\\n",
       "time                                                     \n",
       "2017-01-01           729071                      12933   \n",
       "2017-01-02           730972                      13899   \n",
       "2017-01-03           733490                      13201   \n",
       "2017-01-04           736735                      15979   \n",
       "2017-01-05           739858                      16927   \n",
       "...                     ...                        ...   \n",
       "2021-06-22        120604388                     268881   \n",
       "2021-06-23        120692771                     246050   \n",
       "2021-06-24        120785714                     239936   \n",
       "2021-06-25        120870431                     226995   \n",
       "2021-06-26        120870431                          0   \n",
       "\n",
       "            addresses_sending_count  transactions_transfers_volume_sum  \\\n",
       "time                                                                     \n",
       "2017-01-01                     6215                       1.818131e+06   \n",
       "2017-01-02                     7320                       2.857197e+06   \n",
       "2017-01-03                     8236                       5.066915e+06   \n",
       "2017-01-04                    10535                       7.864367e+06   \n",
       "2017-01-05                     9962                       8.078451e+06   \n",
       "...                             ...                                ...   \n",
       "2021-06-22                   247278                       5.269369e+06   \n",
       "2021-06-23                   251778                       2.275053e+06   \n",
       "2021-06-24                   270342                       2.544816e+06   \n",
       "2021-06-25                   228460                       2.672925e+06   \n",
       "2021-06-26                        0                       3.964921e+06   \n",
       "\n",
       "            mining_hash_rate_mean  mining_difficulty_latest  \\\n",
       "time                                                          \n",
       "2017-01-01           5.646216e+12              8.174688e+13   \n",
       "2017-01-02           5.646488e+12              8.278692e+13   \n",
       "2017-01-03           5.623616e+12              8.197531e+13   \n",
       "2017-01-04           6.200869e+12              8.832221e+13   \n",
       "2017-01-05           6.344418e+12              9.108022e+13   \n",
       "...                           ...                       ...   \n",
       "2021-06-22           4.889401e+14              6.623077e+15   \n",
       "2021-06-23           4.735033e+14              6.530681e+15   \n",
       "2021-06-24           4.731043e+14              6.420884e+15   \n",
       "2021-06-25           4.611892e+14              6.084097e+15   \n",
       "2021-06-26           1.433537e+14              2.051046e+15   \n",
       "\n",
       "            sentiment_analysis  \n",
       "time                            \n",
       "2017-01-01            0.120282  \n",
       "2017-01-02            0.054745  \n",
       "2017-01-03            0.127372  \n",
       "2017-01-04            0.063388  \n",
       "2017-01-05            0.096465  \n",
       "...                        ...  \n",
       "2021-06-22            0.105962  \n",
       "2021-06-23            0.072830  \n",
       "2021-06-24            0.129996  \n",
       "2021-06-25            0.121893  \n",
       "2021-06-26            0.106218  \n",
       "\n",
       "[1451 rows x 15 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=get_data(START_DATE,END_DATE,CRYPTO)\n",
    "df1=read_csv(PATH_BTC)\n",
    "\n",
    "df2=read_csv_tweet(PATH_BTC_TWEET)\n",
    "df_merge=merge_data(df,df1,df2)\n",
    "#print(df_merge.columns)\n",
    "#df_merge=df_merge.drop(columns=[\"coin\"])\n",
    "train_data,test_data=split_data(df_merge,0.99)\n",
    "train_normalized,scaler = normalize_data(train_data)\n",
    "train_loader=create_data_loader(train_normalized)\n",
    "test_loader=create_data_loader_test(test_data,scaler)\n",
    "\n",
    "df_merge\n",
    "#df_merge.to_csv(\"/home/jbouhadoun/esgi/exp/juscrap/outputs/train_btc.csv\")\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# WITH WINDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volumefrom</th>\n",
       "      <th>volumeto</th>\n",
       "      <th>close</th>\n",
       "      <th>addresses_active_count</th>\n",
       "      <th>addresses_new_non_zero_count</th>\n",
       "      <th>addresses_count</th>\n",
       "      <th>addresses_receiving_count</th>\n",
       "      <th>addresses_sending_count</th>\n",
       "      <th>transactions_transfers_volume_sum</th>\n",
       "      <th>mining_hash_rate_mean</th>\n",
       "      <th>mining_difficulty_latest</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>8.891</td>\n",
       "      <td>7.970</td>\n",
       "      <td>8.018</td>\n",
       "      <td>854000.05</td>\n",
       "      <td>6.963217e+06</td>\n",
       "      <td>8.154</td>\n",
       "      <td>13695</td>\n",
       "      <td>1357</td>\n",
       "      <td>729071</td>\n",
       "      <td>12933</td>\n",
       "      <td>6215</td>\n",
       "      <td>1.818131e+06</td>\n",
       "      <td>5.646216e+12</td>\n",
       "      <td>8.174688e+13</td>\n",
       "      <td>0.120282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-02</th>\n",
       "      <td>8.568</td>\n",
       "      <td>7.964</td>\n",
       "      <td>8.154</td>\n",
       "      <td>859902.07</td>\n",
       "      <td>7.152179e+06</td>\n",
       "      <td>8.317</td>\n",
       "      <td>14916</td>\n",
       "      <td>1901</td>\n",
       "      <td>730972</td>\n",
       "      <td>13899</td>\n",
       "      <td>7320</td>\n",
       "      <td>2.857197e+06</td>\n",
       "      <td>5.646488e+12</td>\n",
       "      <td>8.278692e+13</td>\n",
       "      <td>0.054745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>9.940</td>\n",
       "      <td>8.185</td>\n",
       "      <td>8.335</td>\n",
       "      <td>571218.00</td>\n",
       "      <td>5.292232e+06</td>\n",
       "      <td>9.595</td>\n",
       "      <td>14612</td>\n",
       "      <td>2518</td>\n",
       "      <td>733490</td>\n",
       "      <td>13201</td>\n",
       "      <td>8236</td>\n",
       "      <td>5.066915e+06</td>\n",
       "      <td>5.623616e+12</td>\n",
       "      <td>8.197531e+13</td>\n",
       "      <td>0.127372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>11.500</td>\n",
       "      <td>10.240</td>\n",
       "      <td>9.639</td>\n",
       "      <td>2063444.32</td>\n",
       "      <td>2.269524e+07</td>\n",
       "      <td>11.000</td>\n",
       "      <td>17688</td>\n",
       "      <td>3245</td>\n",
       "      <td>736735</td>\n",
       "      <td>15979</td>\n",
       "      <td>10535</td>\n",
       "      <td>7.864367e+06</td>\n",
       "      <td>6.200869e+12</td>\n",
       "      <td>8.832221e+13</td>\n",
       "      <td>0.063388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>10.370</td>\n",
       "      <td>9.151</td>\n",
       "      <td>11.000</td>\n",
       "      <td>2134380.99</td>\n",
       "      <td>2.160218e+07</td>\n",
       "      <td>10.120</td>\n",
       "      <td>18556</td>\n",
       "      <td>3123</td>\n",
       "      <td>739858</td>\n",
       "      <td>16927</td>\n",
       "      <td>9962</td>\n",
       "      <td>8.078451e+06</td>\n",
       "      <td>6.344418e+12</td>\n",
       "      <td>9.108022e+13</td>\n",
       "      <td>0.096465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-22</th>\n",
       "      <td>1998.750</td>\n",
       "      <td>1705.780</td>\n",
       "      <td>1887.890</td>\n",
       "      <td>1703182.02</td>\n",
       "      <td>3.161540e+09</td>\n",
       "      <td>1880.830</td>\n",
       "      <td>516669</td>\n",
       "      <td>91165</td>\n",
       "      <td>120604388</td>\n",
       "      <td>268881</td>\n",
       "      <td>247278</td>\n",
       "      <td>5.269369e+06</td>\n",
       "      <td>4.889401e+14</td>\n",
       "      <td>6.623077e+15</td>\n",
       "      <td>0.105962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-23</th>\n",
       "      <td>2044.910</td>\n",
       "      <td>1827.200</td>\n",
       "      <td>1880.830</td>\n",
       "      <td>714905.63</td>\n",
       "      <td>1.416402e+09</td>\n",
       "      <td>1968.560</td>\n",
       "      <td>512525</td>\n",
       "      <td>88383</td>\n",
       "      <td>120692771</td>\n",
       "      <td>246050</td>\n",
       "      <td>251778</td>\n",
       "      <td>2.275053e+06</td>\n",
       "      <td>4.735033e+14</td>\n",
       "      <td>6.530681e+15</td>\n",
       "      <td>0.072830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-24</th>\n",
       "      <td>2034.570</td>\n",
       "      <td>1886.170</td>\n",
       "      <td>1968.560</td>\n",
       "      <td>448512.52</td>\n",
       "      <td>8.825040e+08</td>\n",
       "      <td>1989.010</td>\n",
       "      <td>523980</td>\n",
       "      <td>92943</td>\n",
       "      <td>120785714</td>\n",
       "      <td>239936</td>\n",
       "      <td>270342</td>\n",
       "      <td>2.544816e+06</td>\n",
       "      <td>4.731043e+14</td>\n",
       "      <td>6.420884e+15</td>\n",
       "      <td>0.129996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-25</th>\n",
       "      <td>2019.450</td>\n",
       "      <td>1791.990</td>\n",
       "      <td>1989.010</td>\n",
       "      <td>882983.22</td>\n",
       "      <td>1.653238e+09</td>\n",
       "      <td>1810.270</td>\n",
       "      <td>454887</td>\n",
       "      <td>84717</td>\n",
       "      <td>120870431</td>\n",
       "      <td>226995</td>\n",
       "      <td>228460</td>\n",
       "      <td>2.672925e+06</td>\n",
       "      <td>4.611892e+14</td>\n",
       "      <td>6.084097e+15</td>\n",
       "      <td>0.121893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-26</th>\n",
       "      <td>1851.360</td>\n",
       "      <td>1717.910</td>\n",
       "      <td>1810.270</td>\n",
       "      <td>575329.88</td>\n",
       "      <td>1.021388e+09</td>\n",
       "      <td>1830.940</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120870431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.964921e+06</td>\n",
       "      <td>1.433537e+14</td>\n",
       "      <td>2.051046e+15</td>\n",
       "      <td>0.106218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1451 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                high       low      open  volumefrom      volumeto     close  \\\n",
       "time                                                                           \n",
       "2017-01-01     8.891     7.970     8.018   854000.05  6.963217e+06     8.154   \n",
       "2017-01-02     8.568     7.964     8.154   859902.07  7.152179e+06     8.317   \n",
       "2017-01-03     9.940     8.185     8.335   571218.00  5.292232e+06     9.595   \n",
       "2017-01-04    11.500    10.240     9.639  2063444.32  2.269524e+07    11.000   \n",
       "2017-01-05    10.370     9.151    11.000  2134380.99  2.160218e+07    10.120   \n",
       "...              ...       ...       ...         ...           ...       ...   \n",
       "2021-06-22  1998.750  1705.780  1887.890  1703182.02  3.161540e+09  1880.830   \n",
       "2021-06-23  2044.910  1827.200  1880.830   714905.63  1.416402e+09  1968.560   \n",
       "2021-06-24  2034.570  1886.170  1968.560   448512.52  8.825040e+08  1989.010   \n",
       "2021-06-25  2019.450  1791.990  1989.010   882983.22  1.653238e+09  1810.270   \n",
       "2021-06-26  1851.360  1717.910  1810.270   575329.88  1.021388e+09  1830.940   \n",
       "\n",
       "            addresses_active_count  addresses_new_non_zero_count  \\\n",
       "time                                                               \n",
       "2017-01-01                   13695                          1357   \n",
       "2017-01-02                   14916                          1901   \n",
       "2017-01-03                   14612                          2518   \n",
       "2017-01-04                   17688                          3245   \n",
       "2017-01-05                   18556                          3123   \n",
       "...                            ...                           ...   \n",
       "2021-06-22                  516669                         91165   \n",
       "2021-06-23                  512525                         88383   \n",
       "2021-06-24                  523980                         92943   \n",
       "2021-06-25                  454887                         84717   \n",
       "2021-06-26                       0                             0   \n",
       "\n",
       "            addresses_count  addresses_receiving_count  \\\n",
       "time                                                     \n",
       "2017-01-01           729071                      12933   \n",
       "2017-01-02           730972                      13899   \n",
       "2017-01-03           733490                      13201   \n",
       "2017-01-04           736735                      15979   \n",
       "2017-01-05           739858                      16927   \n",
       "...                     ...                        ...   \n",
       "2021-06-22        120604388                     268881   \n",
       "2021-06-23        120692771                     246050   \n",
       "2021-06-24        120785714                     239936   \n",
       "2021-06-25        120870431                     226995   \n",
       "2021-06-26        120870431                          0   \n",
       "\n",
       "            addresses_sending_count  transactions_transfers_volume_sum  \\\n",
       "time                                                                     \n",
       "2017-01-01                     6215                       1.818131e+06   \n",
       "2017-01-02                     7320                       2.857197e+06   \n",
       "2017-01-03                     8236                       5.066915e+06   \n",
       "2017-01-04                    10535                       7.864367e+06   \n",
       "2017-01-05                     9962                       8.078451e+06   \n",
       "...                             ...                                ...   \n",
       "2021-06-22                   247278                       5.269369e+06   \n",
       "2021-06-23                   251778                       2.275053e+06   \n",
       "2021-06-24                   270342                       2.544816e+06   \n",
       "2021-06-25                   228460                       2.672925e+06   \n",
       "2021-06-26                        0                       3.964921e+06   \n",
       "\n",
       "            mining_hash_rate_mean  mining_difficulty_latest  \\\n",
       "time                                                          \n",
       "2017-01-01           5.646216e+12              8.174688e+13   \n",
       "2017-01-02           5.646488e+12              8.278692e+13   \n",
       "2017-01-03           5.623616e+12              8.197531e+13   \n",
       "2017-01-04           6.200869e+12              8.832221e+13   \n",
       "2017-01-05           6.344418e+12              9.108022e+13   \n",
       "...                           ...                       ...   \n",
       "2021-06-22           4.889401e+14              6.623077e+15   \n",
       "2021-06-23           4.735033e+14              6.530681e+15   \n",
       "2021-06-24           4.731043e+14              6.420884e+15   \n",
       "2021-06-25           4.611892e+14              6.084097e+15   \n",
       "2021-06-26           1.433537e+14              2.051046e+15   \n",
       "\n",
       "            sentiment_analysis  \n",
       "time                            \n",
       "2017-01-01            0.120282  \n",
       "2017-01-02            0.054745  \n",
       "2017-01-03            0.127372  \n",
       "2017-01-04            0.063388  \n",
       "2017-01-05            0.096465  \n",
       "...                        ...  \n",
       "2021-06-22            0.105962  \n",
       "2021-06-23            0.072830  \n",
       "2021-06-24            0.129996  \n",
       "2021-06-25            0.121893  \n",
       "2021-06-26            0.106218  \n",
       "\n",
       "[1451 rows x 15 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['high', 'low', 'open', 'volumefrom', 'volumeto', 'close',\n",
       "       'addresses_active_count', 'addresses_new_non_zero_count',\n",
       "       'addresses_count', 'addresses_receiving_count',\n",
       "       'addresses_sending_count', 'transactions_transfers_volume_sum',\n",
       "       'mining_hash_rate_mean', 'mining_difficulty_latest',\n",
       "       'sentiment_analysis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=df_merge\n",
    "test_data_size = 100\n",
    "\n",
    "train_data = all_data[:-test_data_size]\n",
    "test_data = all_data[-test_data_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1351\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               high      low     open  volumefrom      volumeto    close  \\\n",
      "time                                                                       \n",
      "2021-03-19  1840.66  1734.36  1776.16   324695.13  5.846494e+08  1809.76   \n",
      "2021-03-20  1868.98  1800.95  1809.76   272549.21  5.002625e+08  1805.49   \n",
      "2021-03-21  1817.33  1747.94  1805.49   343447.52  6.123741e+08  1783.94   \n",
      "2021-03-22  1807.19  1657.58  1783.94   496567.29  8.612933e+08  1682.05   \n",
      "2021-03-23  1721.69  1652.19  1682.05   392868.19  6.646061e+08  1668.69   \n",
      "...             ...      ...      ...         ...           ...      ...   \n",
      "2021-06-22  1998.75  1705.78  1887.89  1703182.02  3.161540e+09  1880.83   \n",
      "2021-06-23  2044.91  1827.20  1880.83   714905.63  1.416402e+09  1968.56   \n",
      "2021-06-24  2034.57  1886.17  1968.56   448512.52  8.825040e+08  1989.01   \n",
      "2021-06-25  2019.45  1791.99  1989.01   882983.22  1.653238e+09  1810.27   \n",
      "2021-06-26  1851.36  1717.91  1810.27   575329.88  1.021388e+09  1830.94   \n",
      "\n",
      "            addresses_active_count  addresses_new_non_zero_count  \\\n",
      "time                                                               \n",
      "2021-03-19                  526487                        155060   \n",
      "2021-03-20                  520471                        146499   \n",
      "2021-03-21                  484380                        131601   \n",
      "2021-03-22                  510487                        146581   \n",
      "2021-03-23                  541122                        144635   \n",
      "...                            ...                           ...   \n",
      "2021-06-22                  516669                         91165   \n",
      "2021-06-23                  512525                         88383   \n",
      "2021-06-24                  523980                         92943   \n",
      "2021-06-25                  454887                         84717   \n",
      "2021-06-26                       0                             0   \n",
      "\n",
      "            addresses_count  addresses_receiving_count  \\\n",
      "time                                                     \n",
      "2021-03-19        106630722                     339085   \n",
      "2021-03-20        106777221                     338843   \n",
      "2021-03-21        106908822                     303386   \n",
      "2021-03-22        107055403                     339177   \n",
      "2021-03-23        107200038                     328313   \n",
      "...                     ...                        ...   \n",
      "2021-06-22        120604388                     268881   \n",
      "2021-06-23        120692771                     246050   \n",
      "2021-06-24        120785714                     239936   \n",
      "2021-06-25        120870431                     226995   \n",
      "2021-06-26        120870431                          0   \n",
      "\n",
      "            addresses_sending_count  transactions_transfers_volume_sum  \\\n",
      "time                                                                     \n",
      "2021-03-19                   247426                       2.176220e+06   \n",
      "2021-03-20                   247310                       1.776790e+06   \n",
      "2021-03-21                   235115                       1.948728e+06   \n",
      "2021-03-22                   237635                       2.707302e+06   \n",
      "2021-03-23                   261700                       2.485138e+06   \n",
      "...                             ...                                ...   \n",
      "2021-06-22                   247278                       5.269369e+06   \n",
      "2021-06-23                   251778                       2.275053e+06   \n",
      "2021-06-24                   270342                       2.544816e+06   \n",
      "2021-06-25                   228460                       2.672925e+06   \n",
      "2021-06-26                        0                       3.964921e+06   \n",
      "\n",
      "            mining_hash_rate_mean  mining_difficulty_latest  \\\n",
      "time                                                          \n",
      "2021-03-19           4.328931e+14              5.798584e+15   \n",
      "2021-03-20           4.429765e+14              6.059984e+15   \n",
      "2021-03-21           4.369401e+14              5.786112e+15   \n",
      "2021-03-22           4.336253e+14              5.767209e+15   \n",
      "2021-03-23           4.380502e+14              5.911065e+15   \n",
      "...                           ...                       ...   \n",
      "2021-06-22           4.889401e+14              6.623077e+15   \n",
      "2021-06-23           4.735033e+14              6.530681e+15   \n",
      "2021-06-24           4.731043e+14              6.420884e+15   \n",
      "2021-06-25           4.611892e+14              6.084097e+15   \n",
      "2021-06-26           1.433537e+14              2.051046e+15   \n",
      "\n",
      "            sentiment_analysis  \n",
      "time                            \n",
      "2021-03-19            0.069398  \n",
      "2021-03-20           -0.025959  \n",
      "2021-03-21            0.149023  \n",
      "2021-03-22            0.183435  \n",
      "2021-03-23            0.129726  \n",
      "...                        ...  \n",
      "2021-06-22            0.105962  \n",
      "2021-06-23            0.072830  \n",
      "2021-06-24            0.129996  \n",
      "2021-06-25            0.121893  \n",
      "2021-06-26            0.106218  \n",
      "\n",
      "[100 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.99968177 -0.99999363 -1.         -0.80950878 -0.99711792 -1.\n",
      "  -1.         -1.         -1.         -1.         -1.         -0.94053307\n",
      "  -0.99989348 -1.         -0.21878073]\n",
      " [-1.         -1.         -0.99986047 -0.80795637 -0.99701925 -0.99983276\n",
      "  -0.99651407 -0.99686525 -0.99996405 -0.99668418 -0.9945514  -0.89539484\n",
      "  -0.9998922  -0.99964005 -0.61055071]\n",
      " [-0.99864824 -0.99976531 -0.99967478 -0.88388881 -0.99799037 -0.99852153\n",
      "  -0.99738198 -0.99330984 -0.99991642 -0.99908008 -0.99003474 -0.79940215\n",
      "  -1.         -0.99992094 -0.17639953]\n",
      " [-0.99711126 -0.99758304 -0.99833697 -0.49138921 -0.98890394 -0.99708\n",
      "  -0.98860006 -0.98912057 -0.99985505 -0.98954454 -0.9786987  -0.67787761\n",
      "  -0.99727926 -0.99772435 -0.558884  ]\n",
      " [-0.99822459 -0.99873948 -0.99694068 -0.47273077 -0.98947464 -0.99798288\n",
      "  -0.98612194 -0.98982358 -0.99979598 -0.98629051 -0.98152408 -0.66857759\n",
      "  -0.99660268 -0.99676984 -0.36115415]]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_normalized[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = torch.FloatTensor(train_data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1351, 15])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_window = 12\n",
    "train_data_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, tw=10):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1]\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(train_data_normalized, train_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[-0.9997, -1.0000, -1.0000, -0.8095, -0.9971, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -0.9405, -0.9999, -1.0000, -0.2188],\n",
       "          [-1.0000, -1.0000, -0.9999, -0.8080, -0.9970, -0.9998, -0.9965, -0.9969,\n",
       "           -1.0000, -0.9967, -0.9946, -0.8954, -0.9999, -0.9996, -0.6106],\n",
       "          [-0.9986, -0.9998, -0.9997, -0.8839, -0.9980, -0.9985, -0.9974, -0.9933,\n",
       "           -0.9999, -0.9991, -0.9900, -0.7994, -1.0000, -0.9999, -0.1764],\n",
       "          [-0.9971, -0.9976, -0.9983, -0.4914, -0.9889, -0.9971, -0.9886, -0.9891,\n",
       "           -0.9999, -0.9895, -0.9787, -0.6779, -0.9973, -0.9977, -0.5589],\n",
       "          [-0.9982, -0.9987, -0.9969, -0.4727, -0.9895, -0.9980, -0.9861, -0.9898,\n",
       "           -0.9998, -0.9863, -0.9815, -0.6686, -0.9966, -0.9968, -0.3612],\n",
       "          [-0.9983, -0.9990, -0.9978, -0.5325, -0.9907, -0.9980, -0.9911, -0.9917,\n",
       "           -0.9997, -0.9926, -0.9819, -0.6973, -0.9964, -0.9973, -0.3534],\n",
       "          [-0.9981, -0.9987, -0.9979, -0.6891, -0.9941, -0.9984, -0.9924, -0.9951,\n",
       "           -0.9997, -0.9929, -0.9893, -0.8283, -0.9954, -0.9956, -0.3209],\n",
       "          [-0.9982, -0.9984, -0.9982, -0.8319, -0.9967, -0.9979, -0.9951, -0.9964,\n",
       "           -0.9997, -0.9950, -0.9936, -0.9108, -0.9952, -0.9951, -0.5294],\n",
       "          [-0.9976, -0.9979, -0.9978, -0.6457, -0.9928, -0.9978, -0.9905, -0.9953,\n",
       "           -0.9996, -0.9929, -0.9831, -0.8279, -0.9942, -0.9941, -0.3496],\n",
       "          [-0.9978, -0.9977, -0.9977, -0.8716, -0.9974, -0.9976, -0.9933, -0.9955,\n",
       "           -0.9996, -0.9934, -0.9910, -0.8201, -0.9940, -0.9943, -0.4810],\n",
       "          [-0.9987, -0.9989, -0.9975, -0.6909, -0.9942, -0.9985, -0.9931, -0.9958,\n",
       "           -0.9995, -0.9931, -0.9869, -0.8190, -0.9938, -0.9942, -0.6780],\n",
       "          [-0.9984, -0.9982, -0.9983, -0.8343, -0.9969, -0.9984, -0.9899, -0.9947,\n",
       "           -0.9995, -0.9917, -0.9896, -0.8218, -0.9935, -0.9942, -0.3365]]),\n",
       "  tensor([[-0.9985, -0.9984, -0.9983, -0.8661, -0.9975, -0.9985, -0.9923, -0.9973,\n",
       "           -0.9995, -0.9940, -0.9946, -0.9111, -0.9928, -0.9928, -0.3770]])),\n",
       " (tensor([[-1.0000, -1.0000, -0.9999, -0.8080, -0.9970, -0.9998, -0.9965, -0.9969,\n",
       "           -1.0000, -0.9967, -0.9946, -0.8954, -0.9999, -0.9996, -0.6106],\n",
       "          [-0.9986, -0.9998, -0.9997, -0.8839, -0.9980, -0.9985, -0.9974, -0.9933,\n",
       "           -0.9999, -0.9991, -0.9900, -0.7994, -1.0000, -0.9999, -0.1764],\n",
       "          [-0.9971, -0.9976, -0.9983, -0.4914, -0.9889, -0.9971, -0.9886, -0.9891,\n",
       "           -0.9999, -0.9895, -0.9787, -0.6779, -0.9973, -0.9977, -0.5589],\n",
       "          [-0.9982, -0.9987, -0.9969, -0.4727, -0.9895, -0.9980, -0.9861, -0.9898,\n",
       "           -0.9998, -0.9863, -0.9815, -0.6686, -0.9966, -0.9968, -0.3612],\n",
       "          [-0.9983, -0.9990, -0.9978, -0.5325, -0.9907, -0.9980, -0.9911, -0.9917,\n",
       "           -0.9997, -0.9926, -0.9819, -0.6973, -0.9964, -0.9973, -0.3534],\n",
       "          [-0.9981, -0.9987, -0.9979, -0.6891, -0.9941, -0.9984, -0.9924, -0.9951,\n",
       "           -0.9997, -0.9929, -0.9893, -0.8283, -0.9954, -0.9956, -0.3209],\n",
       "          [-0.9982, -0.9984, -0.9982, -0.8319, -0.9967, -0.9979, -0.9951, -0.9964,\n",
       "           -0.9997, -0.9950, -0.9936, -0.9108, -0.9952, -0.9951, -0.5294],\n",
       "          [-0.9976, -0.9979, -0.9978, -0.6457, -0.9928, -0.9978, -0.9905, -0.9953,\n",
       "           -0.9996, -0.9929, -0.9831, -0.8279, -0.9942, -0.9941, -0.3496],\n",
       "          [-0.9978, -0.9977, -0.9977, -0.8716, -0.9974, -0.9976, -0.9933, -0.9955,\n",
       "           -0.9996, -0.9934, -0.9910, -0.8201, -0.9940, -0.9943, -0.4810],\n",
       "          [-0.9987, -0.9989, -0.9975, -0.6909, -0.9942, -0.9985, -0.9931, -0.9958,\n",
       "           -0.9995, -0.9931, -0.9869, -0.8190, -0.9938, -0.9942, -0.6780],\n",
       "          [-0.9984, -0.9982, -0.9983, -0.8343, -0.9969, -0.9984, -0.9899, -0.9947,\n",
       "           -0.9995, -0.9917, -0.9896, -0.8218, -0.9935, -0.9942, -0.3365],\n",
       "          [-0.9985, -0.9984, -0.9983, -0.8661, -0.9975, -0.9985, -0.9923, -0.9973,\n",
       "           -0.9995, -0.9940, -0.9946, -0.9111, -0.9928, -0.9928, -0.3770]]),\n",
       "  tensor([[-0.9988, -0.9985, -0.9983, -0.9435, -0.9990, -0.9984, -0.9944, -0.9950,\n",
       "           -0.9994, -0.9954, -0.9958, -0.9788, -0.9926, -0.9924, -0.2796]])),\n",
       " (tensor([[-0.9986, -0.9998, -0.9997, -0.8839, -0.9980, -0.9985, -0.9974, -0.9933,\n",
       "           -0.9999, -0.9991, -0.9900, -0.7994, -1.0000, -0.9999, -0.1764],\n",
       "          [-0.9971, -0.9976, -0.9983, -0.4914, -0.9889, -0.9971, -0.9886, -0.9891,\n",
       "           -0.9999, -0.9895, -0.9787, -0.6779, -0.9973, -0.9977, -0.5589],\n",
       "          [-0.9982, -0.9987, -0.9969, -0.4727, -0.9895, -0.9980, -0.9861, -0.9898,\n",
       "           -0.9998, -0.9863, -0.9815, -0.6686, -0.9966, -0.9968, -0.3612],\n",
       "          [-0.9983, -0.9990, -0.9978, -0.5325, -0.9907, -0.9980, -0.9911, -0.9917,\n",
       "           -0.9997, -0.9926, -0.9819, -0.6973, -0.9964, -0.9973, -0.3534],\n",
       "          [-0.9981, -0.9987, -0.9979, -0.6891, -0.9941, -0.9984, -0.9924, -0.9951,\n",
       "           -0.9997, -0.9929, -0.9893, -0.8283, -0.9954, -0.9956, -0.3209],\n",
       "          [-0.9982, -0.9984, -0.9982, -0.8319, -0.9967, -0.9979, -0.9951, -0.9964,\n",
       "           -0.9997, -0.9950, -0.9936, -0.9108, -0.9952, -0.9951, -0.5294],\n",
       "          [-0.9976, -0.9979, -0.9978, -0.6457, -0.9928, -0.9978, -0.9905, -0.9953,\n",
       "           -0.9996, -0.9929, -0.9831, -0.8279, -0.9942, -0.9941, -0.3496],\n",
       "          [-0.9978, -0.9977, -0.9977, -0.8716, -0.9974, -0.9976, -0.9933, -0.9955,\n",
       "           -0.9996, -0.9934, -0.9910, -0.8201, -0.9940, -0.9943, -0.4810],\n",
       "          [-0.9987, -0.9989, -0.9975, -0.6909, -0.9942, -0.9985, -0.9931, -0.9958,\n",
       "           -0.9995, -0.9931, -0.9869, -0.8190, -0.9938, -0.9942, -0.6780],\n",
       "          [-0.9984, -0.9982, -0.9983, -0.8343, -0.9969, -0.9984, -0.9899, -0.9947,\n",
       "           -0.9995, -0.9917, -0.9896, -0.8218, -0.9935, -0.9942, -0.3365],\n",
       "          [-0.9985, -0.9984, -0.9983, -0.8661, -0.9975, -0.9985, -0.9923, -0.9973,\n",
       "           -0.9995, -0.9940, -0.9946, -0.9111, -0.9928, -0.9928, -0.3770],\n",
       "          [-0.9988, -0.9985, -0.9983, -0.9435, -0.9990, -0.9984, -0.9944, -0.9950,\n",
       "           -0.9994, -0.9954, -0.9958, -0.9788, -0.9926, -0.9924, -0.2796]]),\n",
       "  tensor([[-0.9987, -0.9982, -0.9983, -0.9733, -0.9996, -0.9983, -0.9935, -0.9952,\n",
       "           -0.9994, -0.9932, -0.9964, -0.9941, -0.9921, -0.9917, -0.3028]])),\n",
       " (tensor([[-0.9971, -0.9976, -0.9983, -0.4914, -0.9889, -0.9971, -0.9886, -0.9891,\n",
       "           -0.9999, -0.9895, -0.9787, -0.6779, -0.9973, -0.9977, -0.5589],\n",
       "          [-0.9982, -0.9987, -0.9969, -0.4727, -0.9895, -0.9980, -0.9861, -0.9898,\n",
       "           -0.9998, -0.9863, -0.9815, -0.6686, -0.9966, -0.9968, -0.3612],\n",
       "          [-0.9983, -0.9990, -0.9978, -0.5325, -0.9907, -0.9980, -0.9911, -0.9917,\n",
       "           -0.9997, -0.9926, -0.9819, -0.6973, -0.9964, -0.9973, -0.3534],\n",
       "          [-0.9981, -0.9987, -0.9979, -0.6891, -0.9941, -0.9984, -0.9924, -0.9951,\n",
       "           -0.9997, -0.9929, -0.9893, -0.8283, -0.9954, -0.9956, -0.3209],\n",
       "          [-0.9982, -0.9984, -0.9982, -0.8319, -0.9967, -0.9979, -0.9951, -0.9964,\n",
       "           -0.9997, -0.9950, -0.9936, -0.9108, -0.9952, -0.9951, -0.5294],\n",
       "          [-0.9976, -0.9979, -0.9978, -0.6457, -0.9928, -0.9978, -0.9905, -0.9953,\n",
       "           -0.9996, -0.9929, -0.9831, -0.8279, -0.9942, -0.9941, -0.3496],\n",
       "          [-0.9978, -0.9977, -0.9977, -0.8716, -0.9974, -0.9976, -0.9933, -0.9955,\n",
       "           -0.9996, -0.9934, -0.9910, -0.8201, -0.9940, -0.9943, -0.4810],\n",
       "          [-0.9987, -0.9989, -0.9975, -0.6909, -0.9942, -0.9985, -0.9931, -0.9958,\n",
       "           -0.9995, -0.9931, -0.9869, -0.8190, -0.9938, -0.9942, -0.6780],\n",
       "          [-0.9984, -0.9982, -0.9983, -0.8343, -0.9969, -0.9984, -0.9899, -0.9947,\n",
       "           -0.9995, -0.9917, -0.9896, -0.8218, -0.9935, -0.9942, -0.3365],\n",
       "          [-0.9985, -0.9984, -0.9983, -0.8661, -0.9975, -0.9985, -0.9923, -0.9973,\n",
       "           -0.9995, -0.9940, -0.9946, -0.9111, -0.9928, -0.9928, -0.3770],\n",
       "          [-0.9988, -0.9985, -0.9983, -0.9435, -0.9990, -0.9984, -0.9944, -0.9950,\n",
       "           -0.9994, -0.9954, -0.9958, -0.9788, -0.9926, -0.9924, -0.2796],\n",
       "          [-0.9987, -0.9982, -0.9983, -0.9733, -0.9996, -0.9983, -0.9935, -0.9952,\n",
       "           -0.9994, -0.9932, -0.9964, -0.9941, -0.9921, -0.9917, -0.3028]]),\n",
       "  tensor([[-0.9987, -0.9984, -0.9982, -0.9277, -0.9987, -0.9986, -0.9915, -0.9944,\n",
       "           -0.9993, -0.9917, -0.9889, -0.9846, -0.9922, -0.9918, -0.4522]])),\n",
       " (tensor([[-0.9982, -0.9987, -0.9969, -0.4727, -0.9895, -0.9980, -0.9861, -0.9898,\n",
       "           -0.9998, -0.9863, -0.9815, -0.6686, -0.9966, -0.9968, -0.3612],\n",
       "          [-0.9983, -0.9990, -0.9978, -0.5325, -0.9907, -0.9980, -0.9911, -0.9917,\n",
       "           -0.9997, -0.9926, -0.9819, -0.6973, -0.9964, -0.9973, -0.3534],\n",
       "          [-0.9981, -0.9987, -0.9979, -0.6891, -0.9941, -0.9984, -0.9924, -0.9951,\n",
       "           -0.9997, -0.9929, -0.9893, -0.8283, -0.9954, -0.9956, -0.3209],\n",
       "          [-0.9982, -0.9984, -0.9982, -0.8319, -0.9967, -0.9979, -0.9951, -0.9964,\n",
       "           -0.9997, -0.9950, -0.9936, -0.9108, -0.9952, -0.9951, -0.5294],\n",
       "          [-0.9976, -0.9979, -0.9978, -0.6457, -0.9928, -0.9978, -0.9905, -0.9953,\n",
       "           -0.9996, -0.9929, -0.9831, -0.8279, -0.9942, -0.9941, -0.3496],\n",
       "          [-0.9978, -0.9977, -0.9977, -0.8716, -0.9974, -0.9976, -0.9933, -0.9955,\n",
       "           -0.9996, -0.9934, -0.9910, -0.8201, -0.9940, -0.9943, -0.4810],\n",
       "          [-0.9987, -0.9989, -0.9975, -0.6909, -0.9942, -0.9985, -0.9931, -0.9958,\n",
       "           -0.9995, -0.9931, -0.9869, -0.8190, -0.9938, -0.9942, -0.6780],\n",
       "          [-0.9984, -0.9982, -0.9983, -0.8343, -0.9969, -0.9984, -0.9899, -0.9947,\n",
       "           -0.9995, -0.9917, -0.9896, -0.8218, -0.9935, -0.9942, -0.3365],\n",
       "          [-0.9985, -0.9984, -0.9983, -0.8661, -0.9975, -0.9985, -0.9923, -0.9973,\n",
       "           -0.9995, -0.9940, -0.9946, -0.9111, -0.9928, -0.9928, -0.3770],\n",
       "          [-0.9988, -0.9985, -0.9983, -0.9435, -0.9990, -0.9984, -0.9944, -0.9950,\n",
       "           -0.9994, -0.9954, -0.9958, -0.9788, -0.9926, -0.9924, -0.2796],\n",
       "          [-0.9987, -0.9982, -0.9983, -0.9733, -0.9996, -0.9983, -0.9935, -0.9952,\n",
       "           -0.9994, -0.9932, -0.9964, -0.9941, -0.9921, -0.9917, -0.3028],\n",
       "          [-0.9987, -0.9984, -0.9982, -0.9277, -0.9987, -0.9986, -0.9915, -0.9944,\n",
       "           -0.9993, -0.9917, -0.9889, -0.9846, -0.9922, -0.9918, -0.4522]]),\n",
       "  tensor([[-0.9979, -0.9979, -0.9984, -0.7918, -0.9959, -0.9980, -0.9893, -0.9933,\n",
       "           -0.9993, -0.9892, -0.9907, -0.9519, -0.9925, -0.9930, -0.4269]]))]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=15, hidden_layer_size=100, output_size=15):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(15, 100)\n",
      "  (linear): Linear(in_features=100, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbouhadoun/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([1, 15])) that is different to the input size (torch.Size([15])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/home/jbouhadoun/anaconda3/envs/nlp/lib/python3.8/site-packages/torch/autograd/__init__.py:145: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /opt/conda/conda-bld/pytorch_1616554788289/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 0.08347397\n",
      "epoch:  11 loss: 0.05341026\n",
      "epoch:  21 loss: 0.05265794\n",
      "epoch:  31 loss: 0.05020534\n",
      "epoch:  41 loss: 0.05856584\n",
      "epoch:  51 loss: 0.05853255\n",
      "epoch:  61 loss: 0.07900714\n",
      "epoch:  71 loss: 0.04879310\n",
      "epoch:  81 loss: 0.04955810\n",
      "epoch:  91 loss: 0.03649808\n",
      "epoch: 101 loss: 0.06482140\n",
      "epoch: 111 loss: 0.03799288\n",
      "epoch: 121 loss: 0.03644188\n",
      "epoch: 131 loss: 0.04515873\n",
      "epoch: 141 loss: 0.03689824\n",
      "epoch: 151 loss: 0.04851750\n",
      "epoch: 161 loss: 0.02754503\n",
      "epoch: 171 loss: 0.03241931\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "        #print(y_pred)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%10 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "fut_pred = 10\n",
    "test_inputs = train_data_normalized[-train_window:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "for i in range(fut_pred):\n",
    "    seq = torch.FloatTensor(test_inputs[i:i+train_window])\n",
    "    with torch.no_grad():\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        \n",
    "        predictions.append(model(seq).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.83265881e+03 1.70192218e+03 1.74849096e+03 7.88735084e+05\n",
      "  1.54628855e+09 1.81396625e+03 1.13804474e+06 5.40361770e+05\n",
      "  7.92716278e+08 8.02270682e+05 6.40036491e+05 2.74496746e+06\n",
      "  1.51866428e+20 9.17275343e+22 5.87275595e-02]\n",
      " [1.84166964e+03 1.67760299e+03 1.75171425e+03 9.26399625e+05\n",
      "  1.72120530e+09 1.80096769e+03 1.14747083e+06 5.46937061e+05\n",
      "  7.94038119e+08 8.13268872e+05 6.44337062e+05 2.77730290e+06\n",
      "  1.53480354e+20 9.15909167e+22 5.83695003e-02]\n",
      " [1.85023884e+03 1.64073697e+03 1.75289201e+03 9.76420711e+05\n",
      "  1.92396399e+09 1.78293515e+03 1.17725919e+06 5.70925416e+05\n",
      "  7.96454720e+08 8.44476110e+05 6.56323578e+05 2.74722048e+06\n",
      "  1.56316640e+20 9.24767394e+22 5.51282651e-02]\n",
      " [1.87121930e+03 1.65983633e+03 1.78166201e+03 8.98094591e+05\n",
      "  1.79733333e+09 1.79940019e+03 1.13302728e+06 5.35060421e+05\n",
      "  8.01892620e+08 7.97614269e+05 6.35132606e+05 2.68881149e+06\n",
      "  1.54825935e+20 9.20053674e+22 5.83256071e-02]\n",
      " [1.87313743e+03 1.65039644e+03 1.78425377e+03 9.38111071e+05\n",
      "  1.83976001e+09 1.79093053e+03 1.17008438e+06 5.60644159e+05\n",
      "  8.04437219e+08 8.32048347e+05 6.55983407e+05 2.81286126e+06\n",
      "  1.58248086e+20 9.26865897e+22 5.87840332e-02]\n",
      " [1.90866688e+03 1.64681837e+03 1.82243068e+03 8.78135904e+05\n",
      "  1.93397645e+09 1.80459067e+03 1.15705812e+06 5.43245809e+05\n",
      "  8.09919110e+08 8.04748454e+05 6.54908830e+05 2.60199045e+06\n",
      "  1.60349036e+20 9.36817723e+22 5.73928809e-02]\n",
      " [1.90015963e+03 1.68466315e+03 1.80096362e+03 9.21117491e+05\n",
      "  1.70328140e+09 1.82125939e+03 1.14269721e+06 5.34377132e+05\n",
      "  8.11520394e+08 7.97046505e+05 6.48827425e+05 2.97239825e+06\n",
      "  1.58871422e+20 9.20332800e+22 7.26314622e-02]\n",
      " [1.93875326e+03 1.65107178e+03 1.85033419e+03 9.39559455e+05\n",
      "  2.05276566e+09 1.81590241e+03 1.19077072e+06 5.59848189e+05\n",
      "  8.14845933e+08 8.27487012e+05 6.78096696e+05 2.70665892e+06\n",
      "  1.63511380e+20 9.44038128e+22 5.64034584e-02]\n",
      " [1.93173945e+03 1.72395336e+03 1.81725726e+03 3.97124564e+05\n",
      "  1.30077883e+09 1.86224957e+03 1.07616753e+06 4.94693216e+05\n",
      "  8.34022394e+08 7.44286880e+05 5.91296786e+05 2.43676343e+06\n",
      "  1.53509455e+20 9.31275721e+22 7.50873073e-02]\n",
      " [1.92397644e+03 1.62817656e+03 1.83199434e+03 9.55829166e+05\n",
      "  1.99646048e+09 1.80353405e+03 1.11727940e+06 5.26071173e+05\n",
      "  8.24141078e+08 7.88808233e+05 6.08696072e+05 2.07438489e+06\n",
      "  1.50156965e+20 9.28678396e+22 4.92255306e-02]]\n"
     ]
    }
   ],
   "source": [
    "actual_predictions = scaler.inverse_transform(np.array(predictions ))\n",
    "print(actual_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1813.96625248, 1800.96768779, 1782.93514934, 1799.4001916 ,\n",
       "       1790.93053017, 1804.59067098, 1821.2593913 , 1815.9024141 ,\n",
       "       1862.24957352, 1803.53405469])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_predictions[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volumefrom</th>\n",
       "      <th>volumeto</th>\n",
       "      <th>close</th>\n",
       "      <th>addresses_active_count</th>\n",
       "      <th>addresses_new_non_zero_count</th>\n",
       "      <th>addresses_count</th>\n",
       "      <th>addresses_receiving_count</th>\n",
       "      <th>addresses_sending_count</th>\n",
       "      <th>transactions_transfers_volume_sum</th>\n",
       "      <th>mining_hash_rate_mean</th>\n",
       "      <th>mining_difficulty_latest</th>\n",
       "      <th>sentiment_analysis</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-24</th>\n",
       "      <td>1740.30</td>\n",
       "      <td>1546.93</td>\n",
       "      <td>1668.69</td>\n",
       "      <td>773811.51</td>\n",
       "      <td>1.282635e+09</td>\n",
       "      <td>1583.24</td>\n",
       "      <td>1157951</td>\n",
       "      <td>529959</td>\n",
       "      <td>804691617</td>\n",
       "      <td>780451</td>\n",
       "      <td>699861</td>\n",
       "      <td>1.641230e+06</td>\n",
       "      <td>1.646360e+20</td>\n",
       "      <td>9.391186e+22</td>\n",
       "      <td>0.117733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-25</th>\n",
       "      <td>1621.59</td>\n",
       "      <td>1549.08</td>\n",
       "      <td>1583.24</td>\n",
       "      <td>532202.27</td>\n",
       "      <td>8.454033e+08</td>\n",
       "      <td>1586.98</td>\n",
       "      <td>1206997</td>\n",
       "      <td>562859</td>\n",
       "      <td>805254476</td>\n",
       "      <td>847846</td>\n",
       "      <td>732501</td>\n",
       "      <td>1.713647e+06</td>\n",
       "      <td>1.686305e+20</td>\n",
       "      <td>9.391186e+22</td>\n",
       "      <td>0.108973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-26</th>\n",
       "      <td>1700.19</td>\n",
       "      <td>1586.80</td>\n",
       "      <td>1586.98</td>\n",
       "      <td>398023.77</td>\n",
       "      <td>6.530069e+08</td>\n",
       "      <td>1699.89</td>\n",
       "      <td>1094369</td>\n",
       "      <td>535173</td>\n",
       "      <td>805789649</td>\n",
       "      <td>790536</td>\n",
       "      <td>634876</td>\n",
       "      <td>1.455012e+06</td>\n",
       "      <td>1.473042e+20</td>\n",
       "      <td>9.391186e+22</td>\n",
       "      <td>0.095492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-27</th>\n",
       "      <td>1732.36</td>\n",
       "      <td>1667.18</td>\n",
       "      <td>1699.89</td>\n",
       "      <td>240514.86</td>\n",
       "      <td>4.094073e+08</td>\n",
       "      <td>1713.94</td>\n",
       "      <td>1149816</td>\n",
       "      <td>490264</td>\n",
       "      <td>806279913</td>\n",
       "      <td>722981</td>\n",
       "      <td>733588</td>\n",
       "      <td>1.233196e+06</td>\n",
       "      <td>1.722160e+20</td>\n",
       "      <td>9.391186e+22</td>\n",
       "      <td>0.118015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-28</th>\n",
       "      <td>1725.59</td>\n",
       "      <td>1662.16</td>\n",
       "      <td>1713.94</td>\n",
       "      <td>203653.93</td>\n",
       "      <td>3.456104e+08</td>\n",
       "      <td>1686.74</td>\n",
       "      <td>1070209</td>\n",
       "      <td>430727</td>\n",
       "      <td>806710640</td>\n",
       "      <td>629178</td>\n",
       "      <td>713202</td>\n",
       "      <td>9.208197e+05</td>\n",
       "      <td>1.729981e+20</td>\n",
       "      <td>9.391186e+22</td>\n",
       "      <td>0.066098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-29</th>\n",
       "      <td>1840.88</td>\n",
       "      <td>1676.68</td>\n",
       "      <td>1686.74</td>\n",
       "      <td>485643.56</td>\n",
       "      <td>8.617188e+08</td>\n",
       "      <td>1816.48</td>\n",
       "      <td>1116526</td>\n",
       "      <td>524470</td>\n",
       "      <td>807235110</td>\n",
       "      <td>776748</td>\n",
       "      <td>655259</td>\n",
       "      <td>1.607366e+06</td>\n",
       "      <td>1.648553e+20</td>\n",
       "      <td>9.391186e+22</td>\n",
       "      <td>0.011255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-30</th>\n",
       "      <td>1859.58</td>\n",
       "      <td>1786.81</td>\n",
       "      <td>1816.48</td>\n",
       "      <td>321661.61</td>\n",
       "      <td>5.884028e+08</td>\n",
       "      <td>1841.40</td>\n",
       "      <td>1150659</td>\n",
       "      <td>557303</td>\n",
       "      <td>807792413</td>\n",
       "      <td>826451</td>\n",
       "      <td>668898</td>\n",
       "      <td>1.497385e+06</td>\n",
       "      <td>1.575829e+20</td>\n",
       "      <td>9.391186e+22</td>\n",
       "      <td>0.087737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-31</th>\n",
       "      <td>1947.27</td>\n",
       "      <td>1772.26</td>\n",
       "      <td>1841.40</td>\n",
       "      <td>574695.62</td>\n",
       "      <td>1.070069e+09</td>\n",
       "      <td>1919.08</td>\n",
       "      <td>1245144</td>\n",
       "      <td>599442</td>\n",
       "      <td>808391855</td>\n",
       "      <td>900640</td>\n",
       "      <td>726352</td>\n",
       "      <td>1.362753e+06</td>\n",
       "      <td>1.710658e+20</td>\n",
       "      <td>9.391186e+22</td>\n",
       "      <td>0.115229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-01</th>\n",
       "      <td>1982.01</td>\n",
       "      <td>1888.82</td>\n",
       "      <td>1919.08</td>\n",
       "      <td>452661.12</td>\n",
       "      <td>8.786759e+08</td>\n",
       "      <td>1967.67</td>\n",
       "      <td>1137569</td>\n",
       "      <td>547169</td>\n",
       "      <td>808939024</td>\n",
       "      <td>814582</td>\n",
       "      <td>652437</td>\n",
       "      <td>1.366159e+06</td>\n",
       "      <td>1.577857e+20</td>\n",
       "      <td>9.391186e+22</td>\n",
       "      <td>0.052073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-02</th>\n",
       "      <td>2144.04</td>\n",
       "      <td>1949.57</td>\n",
       "      <td>1967.67</td>\n",
       "      <td>575612.31</td>\n",
       "      <td>1.171559e+09</td>\n",
       "      <td>2134.46</td>\n",
       "      <td>1105972</td>\n",
       "      <td>526362</td>\n",
       "      <td>809465386</td>\n",
       "      <td>795702</td>\n",
       "      <td>637581</td>\n",
       "      <td>1.384211e+06</td>\n",
       "      <td>1.608270e+20</td>\n",
       "      <td>9.937455e+22</td>\n",
       "      <td>0.108007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-03</th>\n",
       "      <td>2138.57</td>\n",
       "      <td>2002.95</td>\n",
       "      <td>2134.46</td>\n",
       "      <td>465878.89</td>\n",
       "      <td>9.665475e+08</td>\n",
       "      <td>2009.19</td>\n",
       "      <td>1024869</td>\n",
       "      <td>475418</td>\n",
       "      <td>809940804</td>\n",
       "      <td>704274</td>\n",
       "      <td>616015</td>\n",
       "      <td>1.342199e+06</td>\n",
       "      <td>1.512374e+20</td>\n",
       "      <td>9.937455e+22</td>\n",
       "      <td>0.062221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               high      low     open  volumefrom      volumeto    close  \\\n",
       "time                                                                       \n",
       "2021-03-24  1740.30  1546.93  1668.69   773811.51  1.282635e+09  1583.24   \n",
       "2021-03-25  1621.59  1549.08  1583.24   532202.27  8.454033e+08  1586.98   \n",
       "2021-03-26  1700.19  1586.80  1586.98   398023.77  6.530069e+08  1699.89   \n",
       "2021-03-27  1732.36  1667.18  1699.89   240514.86  4.094073e+08  1713.94   \n",
       "2021-03-28  1725.59  1662.16  1713.94   203653.93  3.456104e+08  1686.74   \n",
       "2021-03-29  1840.88  1676.68  1686.74   485643.56  8.617188e+08  1816.48   \n",
       "2021-03-30  1859.58  1786.81  1816.48   321661.61  5.884028e+08  1841.40   \n",
       "2021-03-31  1947.27  1772.26  1841.40   574695.62  1.070069e+09  1919.08   \n",
       "2021-04-01  1982.01  1888.82  1919.08   452661.12  8.786759e+08  1967.67   \n",
       "2021-04-02  2144.04  1949.57  1967.67   575612.31  1.171559e+09  2134.46   \n",
       "2021-04-03  2138.57  2002.95  2134.46   465878.89  9.665475e+08  2009.19   \n",
       "\n",
       "            addresses_active_count  addresses_new_non_zero_count  \\\n",
       "time                                                               \n",
       "2021-03-24                 1157951                        529959   \n",
       "2021-03-25                 1206997                        562859   \n",
       "2021-03-26                 1094369                        535173   \n",
       "2021-03-27                 1149816                        490264   \n",
       "2021-03-28                 1070209                        430727   \n",
       "2021-03-29                 1116526                        524470   \n",
       "2021-03-30                 1150659                        557303   \n",
       "2021-03-31                 1245144                        599442   \n",
       "2021-04-01                 1137569                        547169   \n",
       "2021-04-02                 1105972                        526362   \n",
       "2021-04-03                 1024869                        475418   \n",
       "\n",
       "            addresses_count  addresses_receiving_count  \\\n",
       "time                                                     \n",
       "2021-03-24        804691617                     780451   \n",
       "2021-03-25        805254476                     847846   \n",
       "2021-03-26        805789649                     790536   \n",
       "2021-03-27        806279913                     722981   \n",
       "2021-03-28        806710640                     629178   \n",
       "2021-03-29        807235110                     776748   \n",
       "2021-03-30        807792413                     826451   \n",
       "2021-03-31        808391855                     900640   \n",
       "2021-04-01        808939024                     814582   \n",
       "2021-04-02        809465386                     795702   \n",
       "2021-04-03        809940804                     704274   \n",
       "\n",
       "            addresses_sending_count  transactions_transfers_volume_sum  \\\n",
       "time                                                                     \n",
       "2021-03-24                   699861                       1.641230e+06   \n",
       "2021-03-25                   732501                       1.713647e+06   \n",
       "2021-03-26                   634876                       1.455012e+06   \n",
       "2021-03-27                   733588                       1.233196e+06   \n",
       "2021-03-28                   713202                       9.208197e+05   \n",
       "2021-03-29                   655259                       1.607366e+06   \n",
       "2021-03-30                   668898                       1.497385e+06   \n",
       "2021-03-31                   726352                       1.362753e+06   \n",
       "2021-04-01                   652437                       1.366159e+06   \n",
       "2021-04-02                   637581                       1.384211e+06   \n",
       "2021-04-03                   616015                       1.342199e+06   \n",
       "\n",
       "            mining_hash_rate_mean  mining_difficulty_latest  \\\n",
       "time                                                          \n",
       "2021-03-24           1.646360e+20              9.391186e+22   \n",
       "2021-03-25           1.686305e+20              9.391186e+22   \n",
       "2021-03-26           1.473042e+20              9.391186e+22   \n",
       "2021-03-27           1.722160e+20              9.391186e+22   \n",
       "2021-03-28           1.729981e+20              9.391186e+22   \n",
       "2021-03-29           1.648553e+20              9.391186e+22   \n",
       "2021-03-30           1.575829e+20              9.391186e+22   \n",
       "2021-03-31           1.710658e+20              9.391186e+22   \n",
       "2021-04-01           1.577857e+20              9.391186e+22   \n",
       "2021-04-02           1.608270e+20              9.937455e+22   \n",
       "2021-04-03           1.512374e+20              9.937455e+22   \n",
       "\n",
       "            sentiment_analysis  \n",
       "time                            \n",
       "2021-03-24            0.117733  \n",
       "2021-03-25            0.108973  \n",
       "2021-03-26            0.095492  \n",
       "2021-03-27            0.118015  \n",
       "2021-03-28            0.066098  \n",
       "2021-03-29            0.011255  \n",
       "2021-03-30            0.087737  \n",
       "2021-03-31            0.115229  \n",
       "2021-04-01            0.052073  \n",
       "2021-04-02            0.108007  \n",
       "2021-04-03            0.062221  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[12:23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
